{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Verwendete Biblotheken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import json \n",
    "import os \n",
    "import time \n",
    "import kagglehub\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Zweck: Den \"Gesprächskanal\" zwischen Python-Code und dem CouchDB-Server im Docker-Container herstellen und sicherstellen, dass die Zieldatenbank existiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VERBINDUNGS-PARAMETER ---\n",
    "load_dotenv(dotenv_path='.env')\n",
    "COUCHDB_USER = os.getenv(\"COUCHDB_USER\")\n",
    "COUCHDB_PASSWORD = os.getenv(\"COUCHDB_PASSWORD\")\n",
    "COUCHDB_HOST = \"localhost:5984\" \n",
    "COUCHDB_URL = f\"http://{COUCHDB_USER}:{COUCHDB_PASSWORD}@{COUCHDB_HOST}\"\n",
    "DB_NAME = 'world_factbook' \n",
    "\n",
    "try:\n",
    "    server = couchdb.Server(COUCHDB_URL)\n",
    "    print(f\"Erfolgreich mit CouchDB Server verbunden: {server}\")\n",
    "\n",
    "    if DB_NAME in server:\n",
    "        db = server[DB_NAME]\n",
    "        print(f\"Datenbank '{DB_NAME}' existiert bereits.\")\n",
    "    else:\n",
    "        db = server.create(DB_NAME)\n",
    "        print(f\"Datenbank '{DB_NAME}' wurde neu erstellt.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER bei der Verbindung oder Datenbankerstellung: {e}\")\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Arbeitsverzeichnis Pfadanpassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.cwd()\n",
    "if base_dir.name == \"notebooks\":\n",
    "    base_dir = base_dir.parent\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Arbeitsverzeichnis ist bereits korrekt: {base_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURATION ---\n",
    "KAGGLE_DATASET = \"lucafrance/the-world-factbook-by-cia\"\n",
    "EXPECTED_DOC_COUNT = 258 \n",
    "data_dir = base_dir / \"data\"\n",
    "kaggle_cache_path = Path.home() / \".cache\" / \"kagglehub\" / \"datasets\" / \"lucafrance\"\n",
    "\n",
    "print(\"--- Überprüfen des Datenbankstatus ---\")\n",
    "try:\n",
    "    # Zuerst prüfen, ob die Daten schon in der Datenbank sind.\n",
    "    existing_docs = len(db) # Annahme: 'db' Objekt existiert\n",
    "    if existing_docs >= EXPECTED_DOC_COUNT:\n",
    "        print(f\"Datenbank '{DB_NAME}' enthält bereits {existing_docs} Dokumente. Import wird übersprungen.\")\n",
    "    else:\n",
    "        print(f\"Datenbank enthält nur {existing_docs} Dokumente. Starte Datenmigration von Kaggle...\")\n",
    "\n",
    "        # Das lokale data-Verzeichnis sicherstellen\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "            print(f\"Verzeichnis '{data_dir}' wurde erstellt.\")\n",
    "\n",
    "        # Prüfen, ob die Datei bereits lokal existiert\n",
    "        local_json_path = data_dir / \"countries.json\"\n",
    "        if os.path.exists(local_json_path):\n",
    "            print(f\"Datei existiert bereits lokal unter: {local_json_path}\")\n",
    "            json_path = local_json_path\n",
    "        else:\n",
    "            #! --- Download von Kaggle mit kagglehub ---\n",
    "            print(f\"\\n--- Lade Datensatz '{KAGGLE_DATASET}' von Kaggle herunter...\")\n",
    "            \n",
    "            # kagglehub lädt herunter UND entpackt automatisch in das angegebene Verzeichnis\n",
    "            path = kagglehub.dataset_download(KAGGLE_DATASET)\n",
    "            print(f\"Datensatz erfolgreich nach '{path}' heruntergeladen und entpackt.\")\n",
    "                       \n",
    "            # Suche nach der JSON-Datei\n",
    "            json_files = list(Path(path).glob('**/*.json'))\n",
    "            \n",
    "            # Kopiere die Datei in das permanente data-Verzeichnis\n",
    "            source_file = json_files[0]\n",
    "            shutil.copy2(source_file, local_json_path)\n",
    "            print(f\"Datei '{source_file.name}' wurde nach '{local_json_path}' kopiert.\")\n",
    "            \n",
    "            json_path = local_json_path    \n",
    "except Exception as e:\n",
    "    print(f\"\\nEin Fehler ist aufgetreten: {e}\")\n",
    "    raise e\n",
    "\n",
    "finally:\n",
    "    # --- Schritt 5: Aufräumen ---  \n",
    "     # Der kagglehub-Cache löschen\n",
    "    if os.path.exists(kaggle_cache_path):\n",
    "        try:\n",
    "            shutil.rmtree(kaggle_cache_path)\n",
    "            print(f\"kagglehub-Cache unter '{kaggle_cache_path}' wurde gelöscht.\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNUNG: Konnte den kagglehub-Cache nicht löschen: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # --- Verarbeitung der Datei ---\n",
    "print(f\"Verarbeitung der folgenden JSON-Datei: '{json_path}'\")\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "if isinstance(loaded_data, dict):\n",
    "    countries_data = list(loaded_data.values())\n",
    "else: \n",
    "    countries_data = loaded_data\n",
    "\n",
    "print(f\"{len(countries_data)} Länderobjekte für den Import vorbereitet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Laden der Daten in CouchDB ---\n",
    "\n",
    "docs_uploaded = len(db)\n",
    "if docs_uploaded >= EXPECTED_DOC_COUNT:\n",
    "    print(f\"Die Datenbank '{DB_NAME}' enthält bereits {docs_uploaded} Dokumente. Import wird übersprungen.\")\n",
    "else:    \n",
    "    print(f\"\\n--- Speichere {len(countries_data)} Dokumente in CouchDB...\")\n",
    "    start_time = time.time()\n",
    "    for country_doc in countries_data:\n",
    "        country_doc['type'] = 'country'\n",
    "        db.save(country_doc)\n",
    "    end_time = time.time()\n",
    "    print(f\"Alle Dokumente erfolgreich in {end_time - start_time:.2f}s gespeichert.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
