{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Verwendete Biblotheken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import json \n",
    "import os \n",
    "import time \n",
    "import kagglehub\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Struktur der Daten\n",
    "\n",
    "Die Daten stammen aus dem `World Factbook by CIA` und liegen als `JSON` und `CSV` Datei vor. \n",
    "\n",
    "Jedes Land ist ein eigenes Datenobjekt mit vielen Eigenschaften, z.B. Name, Region, Wirtschaftsdaten, Bildungsdaten, Migration und Jugendarbeitslosigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Verbindung zu CouchDB\n",
    "\n",
    "Ein \"Gesprächskanal\" zwischen Python-Code und dem CouchDB-Server im Docker-Container herstellen und sicherstellen, dass die Zieldatenbank existiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VERBINDUNGS-PARAMETER ---\n",
    "load_dotenv(dotenv_path='.env')\n",
    "COUCHDB_USER = os.getenv(\"COUCHDB_USER\")\n",
    "COUCHDB_PASSWORD = os.getenv(\"COUCHDB_PASSWORD\")\n",
    "COUCHDB_HOST = \"localhost:5984\" \n",
    "COUCHDB_URL = f\"http://{COUCHDB_USER}:{COUCHDB_PASSWORD}@{COUCHDB_HOST}\"\n",
    "DB_NAME = 'world_factbook' \n",
    "\n",
    "try:\n",
    "    server = couchdb.Server(COUCHDB_URL)\n",
    "    print(f\"Erfolgreich mit CouchDB Server verbunden: {server}\")\n",
    "\n",
    "    if DB_NAME in server:\n",
    "        db = server[DB_NAME]\n",
    "        print(f\"Datenbank '{DB_NAME}' existiert bereits.\")\n",
    "    else:\n",
    "        db = server.create(DB_NAME)\n",
    "        print(f\"Datenbank '{DB_NAME}' wurde neu erstellt.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER bei der Verbindung oder Datenbankerstellung: {e}\")\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Arbeitsverzeichnis Pfadanpassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.cwd()\n",
    "if base_dir.name == \"notebooks\":\n",
    "    base_dir = base_dir.parent\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Arbeitsverzeichnis {base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Download des Datensatzes zur lokalen Festplatte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURATION ---\n",
    "KAGGLE_DATASET = \"lucafrance/the-world-factbook-by-cia\"\n",
    "EXPECTED_DOC_COUNT = 260 \n",
    "data_dir = base_dir / \"data\"\n",
    "kaggle_cache_path = Path.home() / \".cache\" / \"kagglehub\" / \"datasets\" / \"lucafrance\"\n",
    "\n",
    "print(\"--- Überprüfen des Datenbankstatus ---\")\n",
    "try:\n",
    "    # Zuerst prüfen, ob die Daten schon in der Datenbank sind.\n",
    "    existing_docs = len(db) # Annahme: 'db' Objekt existiert\n",
    "    if existing_docs >= EXPECTED_DOC_COUNT:\n",
    "        print(f\"Datenbank '{DB_NAME}' enthält bereits {existing_docs} Dokumente. Import wird übersprungen.\")\n",
    "    else:\n",
    "        print(f\"Datenbank enthält nur {existing_docs} Dokumente. Starte Datenmigration von Kaggle...\")\n",
    "\n",
    "        # Das lokale data-Verzeichnis sicherstellen\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "            print(f\"Verzeichnis '{data_dir}' wurde erstellt.\")\n",
    "\n",
    "        # Prüfen, ob die Datei bereits lokal existiert\n",
    "        local_json_path = data_dir / \"countries.json\"\n",
    "        if os.path.exists(local_json_path):\n",
    "            print(f\"Datei existiert bereits lokal unter: {local_json_path}\")\n",
    "            json_path = local_json_path\n",
    "        else:\n",
    "            #! --- Download von Kaggle mit kagglehub ---\n",
    "            print(f\"\\n--- Lade Datensatz '{KAGGLE_DATASET}' von Kaggle herunter...\")\n",
    "            path = kagglehub.dataset_download(KAGGLE_DATASET)\n",
    "            print(f\"Datensatz erfolgreich nach '{path}' heruntergeladen und entpackt.\")\n",
    "                       \n",
    "            # Suche nach der JSON-Datei\n",
    "            json_files = list(Path(path).glob('**/*.json'))\n",
    "            \n",
    "            # Kopiere die Datei in das permanente data-Verzeichnis\n",
    "            source_file = json_files[0]\n",
    "            shutil.copy2(source_file, local_json_path)\n",
    "            print(f\"Datei '{source_file.name}' wurde nach '{local_json_path}' kopiert.\")\n",
    "            \n",
    "            json_path = local_json_path    \n",
    "except Exception as e:\n",
    "    print(f\"\\nEin Fehler ist aufgetreten: {e}\")\n",
    "    raise e\n",
    "\n",
    "finally:\n",
    "     # Der kagglehub-Cache löschen\n",
    "    if os.path.exists(kaggle_cache_path):\n",
    "        try:\n",
    "            shutil.rmtree(kaggle_cache_path)\n",
    "            print(f\"kagglehub-Cache unter '{kaggle_cache_path}' wurde gelöscht.\")\n",
    "        except Exception as e:\n",
    "            print(f\"WARNUNG: Konnte den kagglehub-Cache nicht löschen: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Datei vorbereiten\n",
    "Die JSON-Datei öffnen und laden die Daten in Python als Dictionary, um sie als Python Objekte vorliegen zu haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verarbeitung der Datei ---\n",
    "try:\n",
    "    json_path\n",
    "except NameError:\n",
    "    json_path = data_dir / \"countries.json\"\n",
    "    if not json_path.exists():\n",
    "        raise RuntimeError(\"Die Variable 'json_path' ist nicht definiert und die Datei existiert nicht unter dem erwarteten Pfad. Bitte führen Sie zuerst die Zelle für den Download und die Pfadzuweisung aus.\")\n",
    "\n",
    "print(f\"Verarbeitung der folgenden JSON-Datei: '{json_path}'\")\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "documents_for_couchdb = []\n",
    "for country_name, country_data in loaded_data.items(): # country_name ist der Schlüssel, # country_data ist das zugehörige Dictionary\n",
    "    doc = country_data\n",
    "\n",
    "    # Die _ids explizit setzen!\n",
    "    doc['_id'] = country_name\n",
    "    # Das type-Feld \n",
    "    doc['type'] = 'country' \n",
    "    documents_for_couchdb.append(doc)\n",
    "\n",
    "print(f\"{len(documents_for_couchdb)} Länderobjekte für den Import vorbereitet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Import in die Datenbank\n",
    "Alle Länder durchgehen und speichern sie einzeln in CouchDB. Jedes Land bekommt das Feld \"type\": \"country\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_uploaded = len(db)\n",
    "EXPECTED_DOC_COUNT = len(documents_for_couchdb)\n",
    "\n",
    "if docs_uploaded >= EXPECTED_DOC_COUNT:\n",
    "    print(f\"Die Datenbank '{db}' enthält bereits {docs_uploaded} Dokumente. Import wird übersprungen.\")\n",
    "else:\n",
    "    print(f\"\\n--- Speichere {len(documents_for_couchdb)} Dokumente in CouchDB via Bulk-Update... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # db.update() für den schnellen Bulk-Import \n",
    "    db.update(documents_for_couchdb)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Alle Dokumente erfolgreich in {end_time - start_time:.2f}s gespeichert.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
