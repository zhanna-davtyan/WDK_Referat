{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import json\n",
    "import pandas as pd \n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Verbindung zur existierenden Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='.env')\n",
    "COUCHDB_USER = os.getenv(\"COUCHDB_USER\")\n",
    "COUCHDB_PASSWORD = os.getenv(\"COUCHDB_PASSWORD\")\n",
    "COUCHDB_HOST = \"localhost:5984\"  \n",
    "COUCHDB_URL = f\"http://{COUCHDB_USER}:{COUCHDB_PASSWORD}@{COUCHDB_HOST}\"\n",
    "DB_NAME = 'world_factbook' \n",
    "\n",
    "try: \n",
    "    server = couchdb.Server(COUCHDB_URL)\n",
    "    print(f\"Erfolgreich verbunden mit CouchDB unter {COUCHDB_URL}\")\n",
    "    \n",
    "    if DB_NAME in server:\n",
    "        db = server[DB_NAME]\n",
    "        print(f\"Datenbank {DB_NAME} erfolgreich ausgewählt\")\n",
    "    else:\n",
    "        print(f\"Datenbank {DB_NAME} nicht gefunden!\")\n",
    "        raise LookupError(f\"Datenbank {DB_NAME} nicht gefunden!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Verbinden mit CouchDB: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Schlüssel aus allen Dokumenten sammeln:\n",
    "- Dieser Abschnitt dient dazu, alle eindeutigen Schlüssel aus allen Dokumenten einer CouchDB-Datenbank zu extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = set() \n",
    "processed_docs = 0\n",
    "total_docs_in_db = len(db)\n",
    "\n",
    "print(f\"Scanne Schlüssel aus {total_docs_in_db} Dokumenten...\")\n",
    "\n",
    "for doc_id in db:\n",
    "    try:\n",
    "        doc = db[doc_id] \n",
    "        all_keys.update(doc.keys())\n",
    "        processed_docs += 1\n",
    "        # Fortschrittsanzeige alle 100 Dokumente\n",
    "        if processed_docs % 100 == 0:\n",
    "            print(f\"  Verarbeitet {processed_docs}/{total_docs_in_db}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Holen/Verarbeiten von Dokument {doc_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### DataFrame erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "- Alle Dokumente in der Liste all_docs gesammelt, um sie später als DataFrame zu laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "for doc_id in db:\n",
    "    try:\n",
    "        doc = db[doc_id]\n",
    "        all_docs.append(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Holen von Dokument {doc_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_docs)\n",
    "print(f\"Dataset mit allen Dokumenten erstellt: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\n",
    "print(f\"Scannen beendet. {len(all_keys)} eindeutige Schlüssel gefunden.\")\n",
    "\n",
    "df.head(260)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Sortieren und Ausgeben der gefundenen Schlüssel\n",
    "- Die gefundenen Schlüssel werden alphabetisch sortiert und ausgegeben, wobei interne CouchDB-Felder ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(list(all_keys))\n",
    "print(\"\\nGefundene eindeutige Schlüssel (Merkmale):\")\n",
    "for key in sorted_keys:\n",
    "    if key not in ('_id', '_rev', 'type'):\n",
    "        print(f\"- {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Spalten, die keine fehlenden Werte haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing = df.columns[df.isnull().sum() == 0]\n",
    "print(\"Spalten ohne fehlende Werte:\")\n",
    "for col in no_missing:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alle Spalten im DataFrame:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Unnötige Spalten entfernen\n",
    "- Diese Funktion entfernt alle Spalten, die in der gesamten Datenbank keine Werte haben. Dies geschieht, um die Datenbank zu optimieren und nur relevante Informationen zu behalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['_id'].isin(['10019828fd366586c31a18d8fe81ed0c', '10019828fd366586c31a18d8fe840e68'])].index, inplace=True)\n",
    "df.head(260)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "- Die Spalte \"Government: Country name - conventional short form\" direkt nach der Spalte _id zu platzieren, um die Lesbarkeit zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "country_col = \"Government: Country name - conventional short form\"\n",
    "if country_col in cols and \"_id\" in cols:\n",
    "    cols.remove(country_col)\n",
    "    cols.remove(\"_id\")\n",
    "    # Neue Reihenfolge erstellen\n",
    "    new_order = [\"_id\", country_col] + cols\n",
    "    df = df[new_order]\n",
    "    print(\"Spaltenreihenfolge angepasst: Country Name steht direkt nach _id.\")\n",
    "else:\n",
    "    print(\"Spalte 'Government: Country name - conventional short form' oder '_id' nicht gefunden.\")\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Gesamte Erde, zusammengefasst als globale Einheit im CIA World Factbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['_id'] == '10019828fd366586c31a18d8fe89ca31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Spalten, bei denen mindestens 90 % der Werte fehlen \n",
    "- 596 Spalten, wo die 90 % der Werte fehlen\n",
    "- Nach der Bereinigung der Spalten sind insgesamt 387 Spalten übrig geblieben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = df.isnull().mean()\n",
    "cols_90_missing = missing_ratio[missing_ratio >= 0.90].index.tolist()\n",
    "\n",
    "print(\"Spalten mit mindestens 90% fehlenden Werten:\")\n",
    "for col in cols_90_missing:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "df = pd.DataFrame(df.drop(columns=cols_90_missing))\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Ladezeit und Arbeitsspeicher sparen \n",
    "- DataFrame temporär als Pickle-Datei speichern und im neuen Notebook laden, ohne die JSON.xz-Dateien erneut zu verarbeiten\n",
    "- In der Regel ist die Pickle-Datei kleiner als die JSON.xz-Datei\n",
    "\n",
    "#### In neuen Notebook importieren\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_pickle(\"factbook_df.pkl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"factbook_df.pkl\")\n",
    "print(\"DataFrame gespeichert als 'factbook_df.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_df = pd.DataFrame(df.columns, columns=[\"Spaltennamen\"])\n",
    "columns_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
